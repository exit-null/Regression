{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   house age  distance to the nearest MRT station  \\\n",
      "0       32.0                             84.87882   \n",
      "1       19.5                            306.59470   \n",
      "2       13.3                            561.98450   \n",
      "3       13.3                            561.98450   \n",
      "4        5.0                            390.56840   \n",
      "\n",
      "   number of convenience stores  latitude  longitude  house price of unit area  \n",
      "0                            10  24.98298  121.54024                      37.9  \n",
      "1                             9  24.98034  121.53951                      42.2  \n",
      "2                             5  24.98746  121.54391                      47.3  \n",
      "3                             5  24.98746  121.54391                      54.8  \n",
      "4                             5  24.97937  121.54245                      43.1  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"Real estate.csv\")\n",
    "y = df['house price of unit area']\n",
    "df.drop('No', inplace=True, axis=1)\n",
    "df.drop('transaction date', inplace=True, axis=1)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = df.iloc[:100,:-1].values\n",
    "output = df.iloc[:100,-1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.from_numpy(inputs).float()\n",
    "oup = torch.from_numpy(output).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "tensor_dataset = TensorDataset(inp,oup)\n",
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = DataLoader(tensor_dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.0100e+01, 1.2374e+02, 8.0000e+00, 2.4976e+01, 1.2154e+02],\n",
      "        [1.0100e+01, 2.7917e+02, 7.0000e+00, 2.4975e+01, 1.2155e+02],\n",
      "        [1.0400e+01, 2.7645e+02, 5.0000e+00, 2.4956e+01, 1.2154e+02],\n",
      "        [1.6900e+01, 4.0666e+03, 0.0000e+00, 2.4943e+01, 1.2150e+02],\n",
      "        [1.7200e+01, 2.1759e+03, 3.0000e+00, 2.4963e+01, 1.2151e+02]])\n",
      "tensor([[44.3000],\n",
      "        [47.9000],\n",
      "        [33.6000],\n",
      "        [18.3000],\n",
      "        [27.7000]])\n"
     ]
    }
   ],
   "source": [
    "for a, b in train:\n",
    "    print(a)\n",
    "    print(b)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 1.6293e-01,  4.1864e-01,  4.2117e-01,  1.8260e-04, -4.4175e-01]],\n",
       "        requires_grad=True), Parameter containing:\n",
       " tensor([0.3211], requires_grad=True)]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "loss_fn = F.mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.SGD(model.parameters(), lr=0.000000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE loss\n",
    "def mse(t1, t2):\n",
    "    print(\"--------------------------\\n\")\n",
    "    print(t1)\n",
    "    print(\"\\n\\n\")\n",
    "    print(t2)\n",
    "    print(\"--------------------------\\n\")\n",
    "    diff = t1 - t2\n",
    "    return torch.sum(diff * diff) / diff.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(num_epochs, model, loss_fn, opt, train_dl):\n",
    "    \n",
    "    # Repeat for given number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        # Train with batches of data\n",
    "        for xb,yb in train_dl:\n",
    "            \n",
    "            # 5. Reset the gradients to zero\n",
    "            opt.zero_grad()\n",
    "            \n",
    "            # 1. Generate predictions\n",
    "            pred = model(xb)\n",
    "            \n",
    "            # 2. Calculate loss\n",
    "            loss = loss_fn(pred,yb)\n",
    "            \n",
    "            # 3. Compute gradients\n",
    "            loss.backward()\n",
    "            \n",
    "            # 4. Update parameters using gradients\n",
    "            opt.step()\n",
    "        \n",
    "        # Print the progress\n",
    "        if (epoch+1) % 100 == 0:\n",
    "            print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/10000], Loss: 97.4431\n",
      "Epoch [200/10000], Loss: 127.6807\n",
      "Epoch [300/10000], Loss: 127.0707\n",
      "Epoch [400/10000], Loss: 31.2523\n",
      "Epoch [500/10000], Loss: 61.4407\n",
      "Epoch [600/10000], Loss: 40.2186\n",
      "Epoch [700/10000], Loss: 185.8433\n",
      "Epoch [800/10000], Loss: 112.8724\n",
      "Epoch [900/10000], Loss: 210.7195\n",
      "Epoch [1000/10000], Loss: 74.4607\n",
      "Epoch [1100/10000], Loss: 128.5415\n",
      "Epoch [1200/10000], Loss: 169.8896\n",
      "Epoch [1300/10000], Loss: 240.4256\n",
      "Epoch [1400/10000], Loss: 97.1384\n",
      "Epoch [1500/10000], Loss: 111.2803\n",
      "Epoch [1600/10000], Loss: 109.8444\n",
      "Epoch [1700/10000], Loss: 112.2238\n",
      "Epoch [1800/10000], Loss: 121.4437\n",
      "Epoch [1900/10000], Loss: 145.4031\n",
      "Epoch [2000/10000], Loss: 95.0756\n",
      "Epoch [2100/10000], Loss: 105.7113\n",
      "Epoch [2200/10000], Loss: 62.4106\n",
      "Epoch [2300/10000], Loss: 71.5407\n",
      "Epoch [2400/10000], Loss: 51.8589\n",
      "Epoch [2500/10000], Loss: 49.7936\n",
      "Epoch [2600/10000], Loss: 70.1387\n",
      "Epoch [2700/10000], Loss: 221.2426\n",
      "Epoch [2800/10000], Loss: 99.1553\n",
      "Epoch [2900/10000], Loss: 135.2515\n",
      "Epoch [3000/10000], Loss: 397.6208\n",
      "Epoch [3100/10000], Loss: 90.0665\n",
      "Epoch [3200/10000], Loss: 80.8302\n",
      "Epoch [3300/10000], Loss: 106.7023\n",
      "Epoch [3400/10000], Loss: 63.2642\n",
      "Epoch [3500/10000], Loss: 149.6943\n",
      "Epoch [3600/10000], Loss: 158.3865\n",
      "Epoch [3700/10000], Loss: 33.4472\n",
      "Epoch [3800/10000], Loss: 440.7065\n",
      "Epoch [3900/10000], Loss: 123.1597\n",
      "Epoch [4000/10000], Loss: 52.4082\n",
      "Epoch [4100/10000], Loss: 167.8528\n",
      "Epoch [4200/10000], Loss: 48.1251\n",
      "Epoch [4300/10000], Loss: 28.0245\n",
      "Epoch [4400/10000], Loss: 51.5798\n",
      "Epoch [4500/10000], Loss: 66.4858\n",
      "Epoch [4600/10000], Loss: 65.0131\n",
      "Epoch [4700/10000], Loss: 85.7977\n",
      "Epoch [4800/10000], Loss: 73.9069\n",
      "Epoch [4900/10000], Loss: 65.3426\n",
      "Epoch [5000/10000], Loss: 223.7686\n",
      "Epoch [5100/10000], Loss: 187.8046\n",
      "Epoch [5200/10000], Loss: 87.5344\n",
      "Epoch [5300/10000], Loss: 73.8212\n",
      "Epoch [5400/10000], Loss: 311.2956\n",
      "Epoch [5500/10000], Loss: 65.5790\n",
      "Epoch [5600/10000], Loss: 56.6373\n",
      "Epoch [5700/10000], Loss: 121.2950\n",
      "Epoch [5800/10000], Loss: 149.4166\n",
      "Epoch [5900/10000], Loss: 184.6164\n",
      "Epoch [6000/10000], Loss: 44.0989\n",
      "Epoch [6100/10000], Loss: 97.7299\n",
      "Epoch [6200/10000], Loss: 102.4773\n",
      "Epoch [6300/10000], Loss: 62.2006\n",
      "Epoch [6400/10000], Loss: 255.8724\n",
      "Epoch [6500/10000], Loss: 66.1757\n",
      "Epoch [6600/10000], Loss: 106.4929\n",
      "Epoch [6700/10000], Loss: 85.5917\n",
      "Epoch [6800/10000], Loss: 107.7218\n",
      "Epoch [6900/10000], Loss: 101.6903\n",
      "Epoch [7000/10000], Loss: 143.7084\n",
      "Epoch [7100/10000], Loss: 49.7905\n",
      "Epoch [7200/10000], Loss: 148.5293\n",
      "Epoch [7300/10000], Loss: 111.2587\n",
      "Epoch [7400/10000], Loss: 130.6752\n",
      "Epoch [7500/10000], Loss: 95.5558\n",
      "Epoch [7600/10000], Loss: 85.5988\n",
      "Epoch [7700/10000], Loss: 184.7055\n",
      "Epoch [7800/10000], Loss: 109.3084\n",
      "Epoch [7900/10000], Loss: 140.8749\n",
      "Epoch [8000/10000], Loss: 98.7745\n",
      "Epoch [8100/10000], Loss: 53.9283\n",
      "Epoch [8200/10000], Loss: 82.9108\n",
      "Epoch [8300/10000], Loss: 37.4049\n",
      "Epoch [8400/10000], Loss: 122.8246\n",
      "Epoch [8500/10000], Loss: 197.1079\n",
      "Epoch [8600/10000], Loss: 142.2069\n",
      "Epoch [8700/10000], Loss: 257.3135\n",
      "Epoch [8800/10000], Loss: 51.6565\n",
      "Epoch [8900/10000], Loss: 83.5399\n",
      "Epoch [9000/10000], Loss: 94.3200\n",
      "Epoch [9100/10000], Loss: 32.9267\n",
      "Epoch [9200/10000], Loss: 30.1682\n",
      "Epoch [9300/10000], Loss: 161.1238\n",
      "Epoch [9400/10000], Loss: 128.3660\n",
      "Epoch [9500/10000], Loss: 83.1186\n",
      "Epoch [9600/10000], Loss: 114.9648\n",
      "Epoch [9700/10000], Loss: 65.6336\n",
      "Epoch [9800/10000], Loss: 141.8709\n",
      "Epoch [9900/10000], Loss: 103.6415\n",
      "Epoch [10000/10000], Loss: 81.0633\n"
     ]
    }
   ],
   "source": [
    "fit(10000, model, loss_fn, opt, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[48.1908]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.tensor([[10., 101., 12., 30., 122.]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
